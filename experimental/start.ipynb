{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Interactive Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for a strange bug with compute instances \n",
    "import os\n",
    "\n",
    "os.system('sudo cp /etc/nginx/nginx.conf temp.conf') # stupid\n",
    "\n",
    "nginx = ''\n",
    "\n",
    "with open('temp.conf') as f:\n",
    "    for line in f.readlines():\n",
    "        if 'websocket/|/ws/' in line:\n",
    "            nginx += line.replace('websocket/|/ws/', 'websocket/|/ws')\n",
    "        else:\n",
    "            nginx += line\n",
    "       \n",
    "with open('temp2.conf', 'w') as f:\n",
    "    f.write(nginx)\n",
    "    \n",
    "os.system('sudo mv temp2.conf /etc/nginx/nginx.conf')\n",
    "os.system('sudo service nginx restart')\n",
    "os.system('rm temp.conf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception cannot import name '_DistributedTraining'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import socket\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core import Workspace, Experiment, Datastore, Dataset, Environment\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML setup\n",
    "\n",
    "Get the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='dask-cp-testing', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters-dasky-rg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your name\n",
    "\n",
    "Enter your name and virtual network information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Name: dask\n",
      "\n",
      "vNET RG: copeters-dasky-rg\n",
      "vNET name: dasky-vnet\n",
      "vNET subnet name: default\n",
      "\n",
      "Compute target: dask-ct\n",
      "Environment name: dask-env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### name\n",
    "name        = 'dask'             # REPLACE\n",
    "\n",
    "### vnet settings\n",
    "vnet_rg     = ws.resource_group  # replace if needed\n",
    "vnet_name   = 'dasky-vnet'       # replace if needed\n",
    "subnet_name = 'default'          # replace if needed\n",
    "\n",
    "### azure ml names \n",
    "ct_name     = f'{name}-ct'\n",
    "env_name    = f'{name}-env'\n",
    "\n",
    "### trust but verify\n",
    "verify = f'''\n",
    "Name: {name}\n",
    "\n",
    "vNET RG: {vnet_rg}\n",
    "vNET name: {vnet_name}\n",
    "vNET subnet name: {subnet_name}\n",
    "\n",
    "Compute target: {ct_name}\n",
    "Environment name: {env_name}\n",
    "'''\n",
    "\n",
    "print(verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VM pool\n",
    "\n",
    "Create Azure ML VM pool for creating remote dask cluster(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='dask-cp-testing', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters-dasky-rg'), name=dask-ct, id=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/copeters-dasky-rg/providers/Microsoft.MachineLearningServices/workspaces/dask-cp-testing/computes/dask-ct, type=AmlCompute, provisioning_state=Succeeded, location=westeurope, tags=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if ct_name not in ws.compute_targets:\n",
    "    # create config for Azure ML cluster\n",
    "    # change properties as needed\n",
    "    config = AmlCompute.provisioning_configuration(\n",
    "             vm_size                       = 'STANDARD_DS13_V2', # 8 core 56 GiB 112 SSD \n",
    "             min_nodes                     = 0,\n",
    "             max_nodes                     = 100,\n",
    "             vnet_resourcegroup_name       = vnet_rg,              \n",
    "             vnet_name                     = vnet_name,            \n",
    "             subnet_name                   = subnet_name,          \n",
    "             idle_seconds_before_scaledown = 300\n",
    "    )\n",
    "    ct = ComputeTarget.create(ws, ct_name, config)\n",
    "    ct.wait_for_completion(show_output=True)    \n",
    "else:\n",
    "    ct = ws.compute_targets[ct_name]\n",
    "    \n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup cluster\n",
    "\n",
    "Start the run now. The first time, this will take "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Compute Instance code fileshare\n",
    "\n",
    "This will create the compute instance code fileshare as a datastore. The default name `code-391ff5ac-6576-460f-ba4d-7e03433c68b6` and has the same credentials as the default fileshare for the workspace. This will be mounted for easy access to notebooks on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "codefileshare = 'codefileshare'\n",
    "\n",
    "if codefileshare not in ws.datastores:\n",
    "    Datastore.register_azure_file_share(ws, codefileshare,\n",
    "                                        'code-391ff5ac-6576-460f-ba4d-7e03433c68b6',                    \n",
    "                                        account_name = ws.datastores['workspacefilestore'].account_name, \n",
    "                                        account_key  = ws.datastores['workspacefilestore'].account_key   \n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n",
    "\n",
    "This will get NOAA ISD Weather data which is used in the demo. If you already have data, you can skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetExecutionError",
     "evalue": "The operation has been canceled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationCanceled\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_error_handling.py\u001b[0m in \u001b[0;36m_try_execute\u001b[0;34m(action, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/dataflow.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m         self._engine_api.execute_anonymous_activity(ExecuteAnonymousActivityMessageArguments(\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0manonymous_activity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataflow_to_anonymous_activity_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         ))\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mexecute_anonymous_activity\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_anonymous_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecuteAnonymousActivityMessageArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCancellationToken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.ExecuteActivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0mraise_engine_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmessage_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/errorhandlers.py\u001b[0m in \u001b[0;36mraise_engine_error\u001b[0;34m(error_response)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;34m'OperationCanceled'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merror_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOperationCanceled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationCanceled\u001b[0m: The operation has been canceled.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatasetExecutionError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7ff2517b9245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/*/*/*.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sudo chmod 777 /mnt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/isd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatastores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gen2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/data/isd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/noaa-isd'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaskdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/file_dataset.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, target_path, overwrite)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mdataflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataflow_for_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataflow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'download'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FileDataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0m_try_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/dataset_error_handling.py\u001b[0m in \u001b[0;36m_try_execute\u001b[0;34m(action, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDatasetExecutionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mDatasetExecutionError\u001b[0m: The operation has been canceled."
     ]
    }
   ],
   "source": [
    "daskdata = 'noaa-isd-files'\n",
    "\n",
    "if daskdata not in ws.datasets:\n",
    "    ds = Dataset.File.from_files('https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather/*/*/*.parquet', validate=False)\n",
    "    os.system('sudo chmod 777 /mnt')\n",
    "    ds.download('/mnt/data/isd')\n",
    "    ws.datastores['gen2'].upload('/mnt/data/isd', '/noaa-isd')\n",
    "    ds = ds.register(ws, daskdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start cluster\n",
    "\n",
    "This will soon be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_cloudprovider import AzureMLCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = ['mpi4py',\n",
    "            'distributed',\n",
    "            'dask[complete]',\n",
    "            'dask-ml[complete]',\n",
    "            'fastparquet',\n",
    "            'pyarrow',\n",
    "            'jupyterlab',\n",
    "            'joblib',\n",
    "            'notebook',\n",
    "            'adlfs', \n",
    "            'fsspec', \n",
    "            'azureml-sdk[notebooks]',\n",
    "            'azureml-dataprep[fuse]',\n",
    "            'lz4']\n",
    "\n",
    "env = Environment(name=env_name)\n",
    "\n",
    "for package in packages:\n",
    "    env.python.conda_dependencies.add_pip_package(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask-cloudprovider\n",
      "############################## Setting up cluster ##############################\n",
      "########################## Submitting the experiment ###########################\n",
      "####################### Waiting for scheduler node's IP ########################\n",
      "........................................................................................................................................................................................................\n",
      "\n",
      "\n",
      "########################## Scheduler: 10.11.0.12:8786 ##########################\n",
      "############################# Scaling to 1 workers #############################\n",
      "############################### Scaling is done ################################\n"
     ]
    }
   ],
   "source": [
    "cluster = AzureMLCluster(ws, ct, env, jupyter=True, asynchronous=False, datastores=[ws.datastores[datastore] for datastore in ws.datastores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dask-cloudprovider</td><td>dask-cloudprovider_1581220435_df00681e</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/dask-cloudprovider/runs/dask-cloudprovider_1581220435_df00681e?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/copeters-dasky-rg/workspaces/dask-cp-testing\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: dask-cloudprovider,\n",
       "Id: dask-cloudprovider_1581220435_df00681e,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504292413e224da6a05da6c6ed028f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>AzureMLCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up port forwarding...\n",
      "Cluster is ready to use.\n"
     ]
    }
   ],
   "source": [
    "cluster.connect_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cody-9000.westeurope.instances.azureml.net/lab?token=43f429344af211eabfe5000d3aa82394'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.jupyter_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://cody-9001.westeurope.instances.azureml.net/status'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = len(cluster.workers_list)+1\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################### Scheduler and workers are disconnected. ####################\n"
     ]
    }
   ],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class AzureMLCluster in module dask_cloudprovider.providers.azure.azureml:\n",
      "\n",
      "class AzureMLCluster(distributed.deploy.cluster.Cluster)\n",
      " |  Deploy a Dask cluster using Azure ML\n",
      " |  \n",
      " |  This creates a dask scheduler and workers on an Azure ML Compute Target. \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  workspace: azureml.core.Workspace (required)\n",
      " |      Azure ML Workspace - see https://aka.ms/azureml/workspace\n",
      " |  \n",
      " |  compute_target: azureml.core.ComputeTarget (required)\n",
      " |      Azure ML Compute Target - see https://aka.ms/azureml/computetarget\n",
      " |  \n",
      " |  environment_definition: azureml.core.Environment (required)\n",
      " |      Azure ML Environment - see https://aka.ms/azureml/environments\n",
      " |  \n",
      " |  experiment_name: str (optional)\n",
      " |      The name of the Azure ML Experiment used to control the cluster. \n",
      " |  \n",
      " |      Defaults to ``dask-cloudprovider``. \n",
      " |  \n",
      " |  initial_node_count: int (optional)\n",
      " |      The initial number of nodes for the Dask Cluster.\n",
      " |  \n",
      " |      Defaults to ``1``. \n",
      " |  \n",
      " |  use_gpu: bool (optional)\n",
      " |      Flag indicating whether to setup cluster for using GPUs. \n",
      " |  \n",
      " |      Defaults to ``False``. \n",
      " |  \n",
      " |  n_gpus_per_node: int (optional)\n",
      " |      Number of GPUs per node in the Azure ML Compute Target. \n",
      " |  \n",
      " |      Defaults to ``0``. \n",
      " |  \n",
      " |  jupyter: bool (optional)\n",
      " |      Flag to start JupyterLab session on the headnode of the cluster.\n",
      " |  \n",
      " |      Defaults to ``False``. \n",
      " |  \n",
      " |  jupyter_port: int (optional)\n",
      " |      Port on headnode to use for hosting JupyterLab session.\n",
      " |  \n",
      " |      Defaults to ``9000``. \n",
      " |  \n",
      " |  dashboard_port: int (optional)\n",
      " |      Port on headnode to use for hosting Dask dashboard. \n",
      " |  \n",
      " |      Defaults to ``9001``.\n",
      " |  \n",
      " |  datastores: List[str] (optional)\n",
      " |      List of Azure ML Datastores to be mounted on the headnode - \n",
      " |      see https://aka.ms/azureml/data and https://aka.ms/azureml/datastores. \n",
      " |      \n",
      " |      Defaults to ``[]``. To mount all datastores in the workspace, \n",
      " |      set to ``list(workspace.datastores)``. \n",
      " |  \n",
      " |  asynchronous: bool (optional)\n",
      " |      Flag to run jobs asynchronously. \n",
      " |  \n",
      " |  **kwargs: dict\n",
      " |      Additional keyword arguments.\n",
      " |  \n",
      " |  Example | ``AzureMLCluster`` for Dask Client.\n",
      " |  See https://aka.ms/azureml/dask.\n",
      " |  ----------\n",
      " |  ```\n",
      " |  from azureml.core import Workspace\n",
      " |  from dask.distributed import Client\n",
      " |  from dask_cloudprovider import AzureMLCluster\n",
      " |  \n",
      " |  ws = Workspace.from_config()\n",
      " |  \n",
      " |  cluster = AzureMLCluster(ws,\n",
      " |                           ws.compute_targets['dask-ct'],\n",
      " |                           ws.environments['dask-env'])\n",
      " |  \n",
      " |  client = Client(cluster)\n",
      " |  ```\n",
      " |  \n",
      " |  Example | ``AzureMLCluster`` for interactive JupyterLab session. \n",
      " |  See https://aka.ms/azureml/dask.\n",
      " |  ----------\n",
      " |  ```\n",
      " |  from azureml.core import Workspace\n",
      " |  from dask_cloudprovider import AzureMLCluster\n",
      " |  \n",
      " |  ws = Workspace.from_config()\n",
      " |  \n",
      " |  cluster = AzureMLCluster(ws,\n",
      " |                           ws.compute_targets['dask-ct'],\n",
      " |                           ws.environments['dask-env'],\n",
      " |                           datastores=list(ws.datastores),\n",
      " |                           jupyter=True)\n",
      " |  \n",
      " |  print(cluster.jupyter_link)\n",
      " |  print(cluster.dashboard_link)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      AzureMLCluster\n",
      " |      distributed.deploy.cluster.Cluster\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, workspace, compute_target, environment_definition, experiment_name=None, initial_node_count=None, use_gpu=None, n_gpus_per_node=None, jupyter=None, jupyter_port=None, dashboard_port=None, datastores=None, code_store=None, asynchronous=True, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  close(self)\n",
      " |  \n",
      " |  connect_cluster(self)\n",
      " |  \n",
      " |  create_cluster(self)\n",
      " |  \n",
      " |  get_defaults(self)\n",
      " |  \n",
      " |  port_forwarding_ComputeVM(self)\n",
      " |  \n",
      " |  print_links_ComputeVM(self)\n",
      " |  \n",
      " |  scale(self, workers=1)\n",
      " |      Scale cluster to n workers\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n: int\n",
      " |          Target number of workers\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      >>> cluster.scale(10)  # scale cluster to ten workers\n",
      " |  \n",
      " |  scale_down(self, workers=1)\n",
      " |      # scale down\n",
      " |  \n",
      " |  scale_up(self, workers=1)\n",
      " |      # scale up\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dashboard_link\n",
      " |  \n",
      " |  jupyter_link\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from distributed.deploy.cluster.Cluster:\n",
      " |  \n",
      " |  __aenter__(self)\n",
      " |  \n",
      " |  __aexit__(self, typ, value, traceback)\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  adapt(self, Adaptive=<class 'distributed.deploy.adaptive.Adaptive'>, **kwargs) -> distributed.deploy.adaptive.Adaptive\n",
      " |      Turn on adaptivity\n",
      " |      \n",
      " |      For keyword arguments see dask.distributed.Adaptive\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> cluster.adapt(minimum=0, maximum=10, interval='500ms')\n",
      " |  \n",
      " |  logs(self, scheduler=True, workers=True)\n",
      " |      Return logs for the scheduler and workers\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scheduler : boolean\n",
      " |          Whether or not to collect logs for the scheduler\n",
      " |      workers : boolean or Iterable[str], optional\n",
      " |          A list of worker addresses to select.\n",
      " |          Defaults to all workers if `True` or no workers if `False`\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      logs: Dict[str]\n",
      " |          A dictionary of logs, with one item for the scheduler and one for\n",
      " |          each worker\n",
      " |  \n",
      " |  sync(self, func, *args, asynchronous=None, callback_timeout=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from distributed.deploy.cluster.Cluster:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  asynchronous\n",
      " |  \n",
      " |  observed\n",
      " |  \n",
      " |  plan\n",
      " |  \n",
      " |  requested\n",
      " |  \n",
      " |  scheduler_address\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(AzureMLCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
